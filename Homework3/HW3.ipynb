{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to NLP course (2017-2018).\n",
    "\n",
    "### Homework 3: Distributional semantic models.\n",
    "\n",
    "### Jonatan Piñol & Peter Weber\n",
    "\n",
    "Objectives:\n",
    "\n",
    "1) Obtain co-occurrence vector representations with the followin properties:\n",
    "- window size 1, pmi, svd (50)\n",
    "- window size 3, no modifications\n",
    "- window size 3, pmi, no svd\n",
    "- window size 3, no pmi, svd (50)\n",
    "- window size 3, pmi, svd (50)\n",
    "\n",
    "2) Obtain word2vec embeddings with the following properties\n",
    "- window size 1, 50 dimensions\n",
    "- window size 1, 200 dimensions\n",
    "- window size 3, 50 dimensions\n",
    "- window size 3, 200 dimensions\n",
    "- window size 5, 50 dimensions\n",
    "\n",
    "3) Compare the performance of the 10 representations in 1 and 2 on the following tasks:\n",
    "- similarity between \"man\" and \"woman\"\n",
    "- the 5 most similar words to \"car\"\n",
    "- for DISSECT representations , correlation with gold standard\n",
    "- for Word2Vec, the similarity between \"queen\" and \"king + woman - man\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import section\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk import FreqDist\n",
    "from nltk.collocations import *\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import operator\n",
    "from scipy import spatial\n",
    "\n",
    "# Dissect\n",
    "from composes.semantic_space.space import Space\n",
    "from composes.utils import io_utils\n",
    "from composes.transformation.scaling.ppmi_weighting import PpmiWeighting\n",
    "from composes.transformation.dim_reduction.svd import Svd\n",
    "from composes.similarity.cos import CosSimilarity\n",
    "from composes.utils import scoring_utils\n",
    "\n",
    "# Gensim\n",
    "import gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress...1000000\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where the data files are\n",
    "my_path = \"../Data/\"\n",
    "\n",
    "# Loading the matrix from the three different files\n",
    "my_space_1 = Space.build(data = my_path + \"gutenberg_surface_1.sm\",\n",
    "                       rows = my_path + \"gutenberg_surface_1.rows\",\n",
    "                       cols = my_path + \"gutenberg_surface_1.cols\",\n",
    "                       format = \"sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress...1000000\n",
      "Progress...2000000\n",
      "Progress...3000000\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder where the data files are\n",
    "my_path = \"../Data/\"\n",
    "\n",
    "# Loading the matrix from the three different files\n",
    "my_space_3 = Space.build(data = my_path + \"gutenberg_surface_3.sm\",\n",
    "                       rows = my_path + \"gutenberg_surface_3.rows\",\n",
    "                       cols = my_path + \"gutenberg_surface_3.cols\",\n",
    "                       format = \"sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# window size 1, pmi, svd (50)\n",
    "my_ppmi_svd_space_1 = my_space_1.apply(PpmiWeighting()).apply(Svd(50))\n",
    "\n",
    "# window size 3, no modifications\n",
    "my_space_3\n",
    "\n",
    "# window size 3, pmi, no svd\n",
    "my_ppmi_space_3 = my_space_3.apply(PpmiWeighting())\n",
    "\n",
    "# window size 3, no pmi, svd (50)\n",
    "my_svd_space_3 = my_space_3.apply(Svd(50))\n",
    "\n",
    "# window size 3, pmi, svd (50)\n",
    "my_ppmi_svd_space_3 = my_ppmi_space_3.apply(Svd(50))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18421219, 26217850)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the corpus\n",
    "corpus = gutenberg.sents()\n",
    "\n",
    "# Setup word2vec model\n",
    "# NB. word2vec model requires tokenized (and possibly sentence/document \n",
    "# segmented) corpus - list of tokens or list of lists of tokens\n",
    "# If you use a raw corpus, \n",
    "# you need to pre-process it before passing it to w2v.\n",
    "\n",
    "\n",
    "# window size 1, 50 dimensions\n",
    "model_1_50 = gensim.models.Word2Vec (corpus, size=50, window=1, min_count=2, workers=10)\n",
    "model_1_50.train(corpus,total_examples=len(corpus),epochs=10)\n",
    "\n",
    "\n",
    "# window size 1, 200 dimensions\n",
    "model_1_200 = gensim.models.Word2Vec (corpus, size=200, window=1, min_count=2, workers=10)\n",
    "model_1_200.train(corpus,total_examples=len(corpus),epochs=10)\n",
    "\n",
    "# window size 3, 50 dimensions\n",
    "model_3_50 = gensim.models.Word2Vec (corpus, size=50, window=3, min_count=2, workers=10)\n",
    "model_3_50.train(corpus,total_examples=len(corpus),epochs=10)\n",
    "\n",
    "# window size 3, 200 dimensions\n",
    "model_3_200 = gensim.models.Word2Vec (corpus, size=200, window=3, min_count=2, workers=10)\n",
    "model_3_200.train(corpus,total_examples=len(corpus),epochs=10)\n",
    "\n",
    "# window size 5, 50 dimensions\n",
    "model_5_50 = gensim.models.Word2Vec (corpus, size=50, window=5, min_count=2, workers=10)\n",
    "model_5_50.train(corpus,total_examples=len(corpus),epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on the Dissect representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating similarity between man and woman \n",
      "\n",
      "PPMI and SVD matrix window size 1 0.9019762337114995\n",
      "No modifications, window size 3 0.9686231105706885\n",
      "PPMI matrix window size 3 0.10418482739863029\n",
      "SVD matrix window size 3 0.9812513957585547\n",
      "PPMI and SVD matrix window size 3 0.7836632623853524\n",
      "----------------------------------------------\n",
      "\n",
      "Obtaining the 5 most similar words to 'car'\n",
      "\n",
      "PPMI and SVD matrix window size 1 [('car', 1.0), ('table', 0.8509212821582576), ('floor', 0.8463456622201355), ('chimney', 0.8439582387251383), ('dining', 0.8411947312022016)] \n",
      "\n",
      "No modifications, window size 3 [('car', 1.0), ('key', 0.9330561909016643), ('wall', 0.9303721008975641), ('street', 0.930343415021141), ('sea', 0.9249835568137234)] \n",
      "\n",
      "PPMI matrix window size 3 [('car', 1.0), ('bicycles', 0.12817727288119293), ('popping', 0.12467056194780535), ('corpusants', 0.1071900718295629), ('stoical', 0.10669112901298419)] \n",
      "\n",
      "SVD matrix window size 3 [('car', 0.9999999999999998), ('key', 0.9870374477494949), ('lawn', 0.9830738028557786), ('street', 0.9794238089743781), ('level', 0.9787827693562975)] \n",
      "\n",
      "PPMI and SVD matrix window size 3 [('car', 0.9999999999999999), ('stick', 0.8873966984913934), ('window', 0.8837103792755608), ('lawn', 0.876652192818816), ('corner', 0.8755986796086468)] \n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Comparing similarity with 'gold standard'\n",
      "Pairs: [('awful', 'terrible'), ('awful', 'great'), ('awful', 'fast'), ('chop', 'cut'), ('chop', 'bake'), ('chop', 'smile'), ('material', 'fabric'), ('material', 'car'), ('material', 'stone')]\n",
      "Gold scores ['10', '8', '5', '10', '7', '2', '10', '3', '7']\n",
      "\n",
      " PPMI and SVD matrix window size 1:\n",
      "Predicted scores [0.81, 0.52, 0.51, 0.35, 0.42, 0.24, 0.28, 0.12, 0.33]\n",
      "Spearman correlation: 0.4937287878400742\n",
      "Pearson correlation: 0.5248507614047011\n",
      "\n",
      " ---------- \n",
      "\n",
      "Pairs: [('awful', 'terrible'), ('awful', 'great'), ('awful', 'fast'), ('chop', 'cut'), ('chop', 'bake'), ('chop', 'smile'), ('material', 'fabric'), ('material', 'car'), ('material', 'stone')]\n",
      "Gold scores ['10', '8', '5', '10', '7', '2', '10', '3', '7']\n",
      "\n",
      " No PPMI and SVD matrix:\n",
      "Predicted scores [0.84, 0.83, 0.71, 0.56, 0.3, 0.34, 0.41, 0.66, 0.82]\n",
      "Spearman correlation: 0.28942722045797453\n",
      "Pearson correlation: 0.21350087833818576\n",
      "\n",
      " ---------- \n",
      "\n",
      "Pairs: [('awful', 'terrible'), ('awful', 'great'), ('awful', 'fast'), ('chop', 'cut'), ('chop', 'bake'), ('chop', 'smile'), ('material', 'fabric'), ('material', 'car'), ('material', 'stone')]\n",
      "Gold scores ['10', '8', '5', '10', '7', '2', '10', '3', '7']\n",
      "\n",
      " PPMI matrix window size 3:\n",
      "Predicted scores [0.03, 0.03, 0.02, 0.03, 0.0, 0.0, 0.0, 0.01, 0.02]\n",
      "Spearman correlation: 0.4823764451763249\n",
      "Pearson correlation: 0.452079059868903\n",
      "\n",
      " ---------- \n",
      "\n",
      "Pairs: [('awful', 'terrible'), ('awful', 'great'), ('awful', 'fast'), ('chop', 'cut'), ('chop', 'bake'), ('chop', 'smile'), ('material', 'fabric'), ('material', 'car'), ('material', 'stone')]\n",
      "Gold scores ['10', '8', '5', '10', '7', '2', '10', '3', '7']\n",
      "\n",
      " SVD matrix window size 3:\n",
      "Predicted scores [0.93, 0.91, 0.82, 0.63, 0.54, 0.52, 0.59, 0.74, 0.91]\n",
      "Spearman correlation: 0.33765617369326306\n",
      "Pearson correlation: 0.22142573694642415\n",
      "\n",
      " ---------- \n",
      "\n",
      "Pairs: [('awful', 'terrible'), ('awful', 'great'), ('awful', 'fast'), ('chop', 'cut'), ('chop', 'bake'), ('chop', 'smile'), ('material', 'fabric'), ('material', 'car'), ('material', 'stone')]\n",
      "Gold scores ['10', '8', '5', '10', '7', '2', '10', '3', '7']\n",
      "\n",
      " PPMI and SVD matrix window size 3:\n",
      "Predicted scores [0.85, 0.48, 0.49, 0.42, 0.33, 0.21, 0.31, 0.32, 0.33]\n",
      "Spearman correlation: 0.41886462053088325\n",
      "Pearson correlation: 0.5188465567760774\n",
      "\n",
      " ---------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Comparing similarity between \"man\" and \"woman\"\n",
    "print \"Calculating similarity between man and woman\",\"\\n\"\n",
    "print \"PPMI and SVD matrix window size 1\",my_ppmi_svd_space_1.get_sim(\"man\", \"woman\", CosSimilarity())\n",
    "print \"No modifications, window size 3\",my_space_3.get_sim(\"man\", \"woman\", CosSimilarity())\n",
    "print \"PPMI matrix window size 3\",my_ppmi_space_3.get_sim(\"man\", \"woman\", CosSimilarity())\n",
    "print \"SVD matrix window size 3\",my_svd_space_3.get_sim(\"man\", \"woman\", CosSimilarity())\n",
    "print \"PPMI and SVD matrix window size 3\",my_ppmi_svd_space_3.get_sim(\"man\", \"woman\", CosSimilarity())\n",
    "print \"----------------------------------------------\\n\"\n",
    "\n",
    "# Comparing the 5 most similar words to \"car\"\n",
    "print \"Obtaining the 5 most similar words to 'car'\\n\"\n",
    "print \"PPMI and SVD matrix window size 1\",my_ppmi_svd_space_1.get_neighbours(\"car\", 5, CosSimilarity()),\"\\n\"\n",
    "print \"No modifications, window size 3\",my_space_3.get_neighbours(\"car\", 5, CosSimilarity()),\"\\n\"\n",
    "print \"PPMI matrix window size 3\",my_ppmi_space_3.get_neighbours(\"car\", 5, CosSimilarity()),\"\\n\"\n",
    "print \"SVD matrix window size 3\",my_svd_space_3.get_neighbours(\"car\", 5, CosSimilarity()),\"\\n\"\n",
    "print \"PPMI and SVD matrix window size 3\",my_ppmi_svd_space_3.get_neighbours(\"car\", 5, CosSimilarity()),\"\\n\"\n",
    "print \"----------------------------------------------\\n\"\n",
    "\n",
    "\n",
    "# Comparing the similarity with \"gold standard\"\n",
    "print \"Comparing similarity with 'gold standard'\"\n",
    "fname = my_path + \"synonyms.txt\"\n",
    "# Load the pairs\n",
    "word_pairs = io_utils.read_tuple_list(fname, fields=[0,1])\n",
    "# Load the score\n",
    "gold = io_utils.read_list(fname, field=2)\n",
    "# Predict similarity\n",
    "predicted_ppmi_svd = [round(sim,2) for sim in my_ppmi_svd_space_1.get_sims(word_pairs, CosSimilarity())]\n",
    "print \"Pairs:\",word_pairs\n",
    "print \"Gold scores\",gold\n",
    "print \"\\n PPMI and SVD matrix window size 1:\"\n",
    "print \"Predicted scores\",predicted_ppmi_svd\n",
    "print \"Spearman correlation:\",scoring_utils.score(gold, predicted_ppmi_svd, \"spearman\")\n",
    "print \"Pearson correlation:\",scoring_utils.score(gold, predicted_ppmi_svd, \"pearson\")\n",
    "print \"\\n ---------- \\n\"\n",
    "\n",
    "predicted_ppmi_svd = [round(sim,2) for sim in my_space_3.get_sims(word_pairs, CosSimilarity())]\n",
    "print \"\\n No PPMI and SVD matrix:\"\n",
    "print \"Predicted scores\",predicted_ppmi_svd\n",
    "print \"Spearman correlation:\",scoring_utils.score(gold, predicted_ppmi_svd, \"spearman\")\n",
    "print \"Pearson correlation:\",scoring_utils.score(gold, predicted_ppmi_svd, \"pearson\")\n",
    "print \"\\n ---------- \\n\"\n",
    "\n",
    "predicted_ppmi_svd = [round(sim,2) for sim in my_ppmi_space_3.get_sims(word_pairs, CosSimilarity())]\n",
    "print \"\\n PPMI matrix window size 3:\"\n",
    "print \"Predicted scores\",predicted_ppmi_svd\n",
    "print \"Spearman correlation:\",scoring_utils.score(gold, predicted_ppmi_svd, \"spearman\")\n",
    "print \"Pearson correlation:\",scoring_utils.score(gold, predicted_ppmi_svd, \"pearson\")\n",
    "print \"\\n ---------- \\n\"\n",
    "\n",
    "predicted_ppmi_svd = [round(sim,2) for sim in my_svd_space_3.get_sims(word_pairs, CosSimilarity())]\n",
    "print \"\\n SVD matrix window size 3:\"\n",
    "print \"Predicted scores\",predicted_ppmi_svd\n",
    "print \"Spearman correlation:\",scoring_utils.score(gold, predicted_ppmi_svd, \"spearman\")\n",
    "print \"Pearson correlation:\",scoring_utils.score(gold, predicted_ppmi_svd, \"pearson\")\n",
    "print \"\\n ---------- \\n\"\n",
    "\n",
    "predicted_ppmi_svd = [round(sim,2) for sim in my_ppmi_svd_space_3.get_sims(word_pairs, CosSimilarity())]\n",
    "print \"\\n PPMI and SVD matrix window size 3:\"\n",
    "print \"Predicted scores\",predicted_ppmi_svd\n",
    "print \"Spearman correlation:\",scoring_utils.score(gold, predicted_ppmi_svd, \"spearman\")\n",
    "print \"Pearson correlation:\",scoring_utils.score(gold, predicted_ppmi_svd, \"pearson\")\n",
    "print \"\\n ---------- \\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance on the Word2Vec representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "window size 1, 50 dimensions\n",
      "\n",
      "The similarity between ``man'' and ``woman'' is: 0.882613873325\n",
      "\n",
      "The five words most similar to car are: [(u'lane', 0.7859511375427246), (u'cabin', 0.7837317585945129), (u'breeze', 0.7645677328109741), (u'bushes', 0.7635990381240845), (u'shutters', 0.7610712051391602)]\n",
      "\n",
      "The similarity between ``queen'' and ``king - man + woman'' is 0.555125713348\n",
      "\n",
      "-------------\n",
      "\n",
      "window size 1, 200 dimensions\n",
      "\n",
      "The similarity between ``man'' and ``woman'' is: 0.66602621464\n",
      "\n",
      "The five words most similar to car are: [(u'shopman', 0.7213327288627625), (u'bushes', 0.7186962366104126), (u'lane', 0.7164766788482666), (u'shutters', 0.7156256437301636), (u'dial', 0.7134419679641724)]\n",
      "\n",
      "The similarity between ``queen'' and ``king - man + woman'' is 0.418639153242\n",
      "\n",
      "-------------\n",
      "\n",
      "window size 3, 50 dimensions\n",
      "\n",
      "The similarity between ``man'' and ``woman'' is: 0.833102187214\n",
      "\n",
      "The five words most similar to car are: [(u'lane', 0.858578085899353), (u'coach', 0.8423855304718018), (u'boat', 0.841621458530426), (u'hedge', 0.8336536288261414), (u'bushes', 0.8220893144607544)]\n",
      "\n",
      "The similarity between ``queen'' and ``king - man + woman'' is 0.536764681339\n",
      "\n",
      "-------------\n",
      "\n",
      "window size 3, 200 dimensions\n",
      "\n",
      "The similarity between ``man'' and ``woman'' is: 0.654378859085\n",
      "\n",
      "The five words most similar to car are: [(u'coach', 0.7723888158798218), (u'boat', 0.757004976272583), (u'lane', 0.7437072992324829), (u'bushes', 0.7363449335098267), (u'floor', 0.7318230867385864)]\n",
      "\n",
      "The similarity between ``queen'' and ``king - man + woman'' is 0.470824837685\n",
      "\n",
      "-------------\n",
      "\n",
      "window size 5, 50 dimensions\n",
      "\n",
      "The similarity between ``man'' and ``woman'' is: 0.717899873741\n",
      "\n",
      "The five words most similar to car are: [(u'boat', 0.8176566362380981), (u'lane', 0.8145003318786621), (u'pole', 0.8056381940841675), (u'line', 0.8006017804145813), (u'stick', 0.7954979538917542)]\n",
      "\n",
      "The similarity between ``queen'' and ``king - man + woman'' is 0.598008930683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonatanpinol/anaconda3/envs/NLTK27/lib/python2.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/jonatanpinol/anaconda3/envs/NLTK27/lib/python2.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/jonatanpinol/anaconda3/envs/NLTK27/lib/python2.7/site-packages/ipykernel_launcher.py:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/Users/jonatanpinol/anaconda3/envs/NLTK27/lib/python2.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/Users/jonatanpinol/anaconda3/envs/NLTK27/lib/python2.7/site-packages/ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/Users/jonatanpinol/anaconda3/envs/NLTK27/lib/python2.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/Users/jonatanpinol/anaconda3/envs/NLTK27/lib/python2.7/site-packages/ipykernel_launcher.py:49: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/Users/jonatanpinol/anaconda3/envs/NLTK27/lib/python2.7/site-packages/ipykernel_launcher.py:50: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/Users/jonatanpinol/anaconda3/envs/NLTK27/lib/python2.7/site-packages/ipykernel_launcher.py:62: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/Users/jonatanpinol/anaconda3/envs/NLTK27/lib/python2.7/site-packages/ipykernel_launcher.py:63: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nwindow size 1, 50 dimensions\")\n",
    "# Calculate the similarity between \"man\" and \"woman\"\n",
    "print(\"\\nThe similarity between ``man'' and ``woman'' is: {}\".format (model_1_50.wv.similarity(w1=\"man\",w2=\"woman\")))\n",
    "\n",
    "# Get the 5 words most similar to \"Car\"\n",
    "print (\"\\nThe five words most similar to car are: {}\".format(model_1_50.wv.most_similar (positive=\"car\", topn=5)))\n",
    "\n",
    "# Substract \"man\" from \"king\", add \"woman\" and compare with \"queen\"\n",
    "custom_queen = np.add(np.subtract(model_1_50[\"king\"],model_1_50[\"man\"]),model_1_50[\"woman\"])\n",
    "print(\"\\nThe similarity between ``queen'' and ``king - man + woman'' is {}\".format(1 - spatial.distance.cosine(custom_queen,model_1_50[\"queen\"])))\n",
    "\n",
    "print(\"\\n-------------\\n\")\n",
    "\n",
    "print(\"window size 1, 200 dimensions\")\n",
    "# Calculate the similarity between \"man\" and \"woman\"\n",
    "print(\"\\nThe similarity between ``man'' and ``woman'' is: {}\".format (model_1_200.wv.similarity(w1=\"man\",w2=\"woman\")))\n",
    "\n",
    "# Get the 5 words most similar to \"Car\"\n",
    "print (\"\\nThe five words most similar to car are: {}\".format(model_1_200.wv.most_similar (positive=\"car\", topn=5)))\n",
    "\n",
    "# Substract \"man\" from \"king\", add \"woman\" and compare with \"queen\"\n",
    "custom_queen = np.add(np.subtract(model_1_200[\"king\"],model_1_200[\"man\"]),model_1_200[\"woman\"])\n",
    "print(\"\\nThe similarity between ``queen'' and ``king - man + woman'' is {}\".format(1 - spatial.distance.cosine(custom_queen,model_1_200[\"queen\"])))\n",
    "\n",
    "print(\"\\n-------------\\n\")\n",
    "\n",
    "print(\"window size 3, 50 dimensions\")\n",
    "# Calculate the similarity between \"man\" and \"woman\"\n",
    "print(\"\\nThe similarity between ``man'' and ``woman'' is: {}\".format (model_3_50.wv.similarity(w1=\"man\",w2=\"woman\")))\n",
    "\n",
    "# Get the 5 words most similar to \"Car\"\n",
    "print (\"\\nThe five words most similar to car are: {}\".format(model_3_50.wv.most_similar (positive=\"car\", topn=5)))\n",
    "\n",
    "# Substract \"man\" from \"king\", add \"woman\" and compare with \"queen\"\n",
    "custom_queen = np.add(np.subtract(model_3_50[\"king\"],model_3_50[\"man\"]),model_3_50[\"woman\"])\n",
    "print(\"\\nThe similarity between ``queen'' and ``king - man + woman'' is {}\".format(1 - spatial.distance.cosine(custom_queen,model_3_50[\"queen\"])))\n",
    "\n",
    "print(\"\\n-------------\\n\")\n",
    "\n",
    "print(\"window size 3, 200 dimensions\")\n",
    "# Calculate the similarity between \"man\" and \"woman\"\n",
    "print(\"\\nThe similarity between ``man'' and ``woman'' is: {}\".format (model_3_200.wv.similarity(w1=\"man\",w2=\"woman\")))\n",
    "\n",
    "# Get the 5 words most similar to \"Car\"\n",
    "print (\"\\nThe five words most similar to car are: {}\".format(model_3_200.wv.most_similar (positive=\"car\", topn=5)))\n",
    "\n",
    "# Substract \"man\" from \"king\", add \"woman\" and compare with \"queen\"\n",
    "custom_queen = np.add(np.subtract(model_3_200[\"king\"],model_3_200[\"man\"]),model_3_200[\"woman\"])\n",
    "print(\"\\nThe similarity between ``queen'' and ``king - man + woman'' is {}\".format(1 - spatial.distance.cosine(custom_queen,model_3_200[\"queen\"])))\n",
    "\n",
    "print(\"\\n-------------\\n\")\n",
    "\n",
    "print(\"window size 5, 50 dimensions\")\n",
    "# Calculate the similarity between \"man\" and \"woman\"\n",
    "print(\"\\nThe similarity between ``man'' and ``woman'' is: {}\".format (model_5_50.wv.similarity(w1=\"man\",w2=\"woman\")))\n",
    "\n",
    "# Get the 5 words most similar to \"Car\"\n",
    "print (\"\\nThe five words most similar to car are: {}\".format(model_5_50.wv.most_similar (positive=\"car\", topn=5)))\n",
    "\n",
    "# Substract \"man\" from \"king\", add \"woman\" and compare with \"queen\"\n",
    "custom_queen = np.add(np.subtract(model_5_50[\"king\"],model_5_50[\"man\"]),model_5_50[\"woman\"])\n",
    "print(\"\\nThe similarity between ``queen'' and ``king - man + woman'' is {}\".format(1 - spatial.distance.cosine(custom_queen,model_5_50[\"queen\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
